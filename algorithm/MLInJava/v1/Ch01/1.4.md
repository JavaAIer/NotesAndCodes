### 1.4 数据预处理

目标：用最可靠的方式为机器学习算法准备数据，因为并非所有算法都可以用于处理缺少数据、额外属性以及非标准值。

#### 1.4.1  数据清洗（数据整理，数据清理）

处理过程：

- 识别不准确、不完整、不相关、已损坏的数据，并在进一步处理之前移除。
- 分析数据，提取感兴趣的信息，或者验证数据格式是否合法
- 将数据转换为常见的编码格式，比如utf-8、int32、时标或者标准范围
- 将数据转换为常见数据模式，比如如果收集的温度数据来自不同类型的传感器，那么可能需要将其变换为具有相同结构的数据。

#### 1.4.2 填充缺失值

历史背景：一般来说，对于缺失值，机器学习算法工作得不是很好。但是极少数例外，比如决策树、朴素贝叶斯分类器，以及一些基于规则的学习器等。

值缺失原因：随机误差、系统误差、传感器噪声等。

根据不同的值缺失原因，处理方法如下：

- 移除实例：数据足够多，只有几个相关实例有一些缺失值的情况下，就移除掉这几行数据，这个操作是安全的。
- 移除属性：当大部分值缺失、值为常量，或者当前属性与另一个属性有强相关关系时，移除该属性是有意义的。
- 指派为特殊值N/A：缺失值是由正当原因引起的，比如值超出指定范围、离散属性值未定义、无法获取或测量得到的值——这个值也可能是指示器（indicator）。比如，一个人从来不评价电影，那么淘票票购买记录上他对这个电影的评分就不存在。
- 填入属性平均值：如果拥有的实例数量有限，那么不能够移除实例或属性。这种情况下，我们可以对缺失值进行估算，比如把属性的平均值或相似实例的平均值作为缺失值进行填充。
- 依据其他属性值进行预测：如果属性有时间依赖关系，那么可以根据之前的已有值预测缺失值。

综上所述：出现缺失值的原因多种多样，因此了解值缺失或损坏的原因非常重要。



#### 1.4.3 剔除异常值

异常值：指数据中那些与其他数值相比有较大差异的数值，这些异常值对所有学习算法都有不同程度的影响。异常值可能是极端值，可以通过置信区域检测，并可借助阈值剔除。最好的办法是选对数据进行可视化，然后检查可视化图形，从中找出异常值。

#### 1.4.4 数据转换

数据转换技术将数据集转换为机器学习算法要求的格式，用作机器学习算法的输入。数据转换甚至可以帮助算法学得更快，获得更好的性能，比如标准化。假设数据服从高斯分布，采用如下方式做值变换：均值为0，标准差为1。

另一方面，归一化将属性值按比例缩放，使之落入一个小的特定区间，通常是[0，1]。

最后一个变换技术是离散化，用于将一个连续特征的范围分为若干区间。因为有些算法，比如决策树、朴素贝叶斯算法，更擅长处理离散属性。最常用的选取区间（离散化）的方法如下。其中前两个方法需要手工指定区间数量，而最后一种方法则自动设置区间数量。但后者需要分类变量，这意味着它不能用于无监督机器学习任务。

- 等宽离散化：该方法将连续变量的值域划分成k个具有相同宽度的区间。
- 等频离散化：假设有N个实例，k个区间中的每一个都包含大约N/k个实例。
- 最小熵（度量体系的混乱程度）离散化：该方法会递归地分割区间，直到区间分割引起的熵减大于熵增。



#### 1.4.5 数据规约

数据归约用于处理大量属性与实例，属性数对应于数据集的维度数。具有较低预测能力的维度不仅对整个模型的贡献率非常小，还会带来许多危害。比如，一个拥有随机值的属性可能产生一些随机模式，这些随机模式会被机器学习算法识别。

解决方法

- 特征选取（属性选取）：把随机属性剔除，换言之，只保留那些最看好的属性。具体可使用的方法有ReliefF、信息增益、基尼指数等，它们主要面向离散属性。
- 抽象降维：将数据集从原始维度转换到低维空间。例如，假设有一组三维空间中的点，我们可以将其映射到二维空间。这个过程中会丢失一些信息，但如果第三个维度是不相关的，则不会丢失很多信息，数据结构与相关性几乎都能完美保留，主要面向连续属性。常用方法如下：
  - 奇异值分解（SVD）
  - 主成分分析（PCA）
  - 神经网络自动编码器（Neural nets auto encoders）

数据规约中的第二个问题是数据包含太多实例。这么多个实例可能是重复的，或者来自一个非常频繁的数据流。解决这个问题的方法是从中选用实例子集，选择时要保证所选数据的分布与原数据的分布相似，更重要的是观测的过程类似。减少实例数量的技术包括随机数据采样、数据分层法等。准备好数据后，接下来对数据进行分析与建模。

